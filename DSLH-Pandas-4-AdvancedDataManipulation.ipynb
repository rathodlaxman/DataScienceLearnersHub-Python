{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# **`Data Science Learners Hub`**\n",
                "\n",
                "**Module : Python**\n",
                "\n",
                "**email** : [datasciencelearnershub@gmail.com](mailto:datasciencelearnershub@gmail.com)"
            ],
            "metadata": {
                "azdata_cell_guid": "dc89a9f6-e252-4a23-92f7-a45bf4a58bb1"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **`#4: Advanced Data Manipulation`**\n",
                "10. **Merging and Concatenating DataFrames**\n",
                "    - Combining DataFrames\n",
                "    - Concatenation and merging operations\n",
                "\n",
                "11. **Reshaping Data**\n",
                "    - Pivoting and melting\n",
                "    - Stacking and unstacking\n",
                "\n",
                "12. **Time Series Data**\n",
                "    - Handling time and date data\n",
                "    - Resampling and frequency conversion"
            ],
            "metadata": {
                "azdata_cell_guid": "2dfff4bf-f9de-4fe6-85f4-41599e6fe25d"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **`10. Merging and Concatenating DataFrames`**"
            ],
            "metadata": {
                "azdata_cell_guid": "9db3e042-09e1-4fa5-884f-4e43b3cea395"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### **`Combining DataFrames in Pandas`**"
            ],
            "metadata": {
                "azdata_cell_guid": "d255e23f-9379-4cec-8b42-bb740eaec562"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Concept of Combining DataFrames:\n",
                "\n",
                "Combining or merging DataFrames in Pandas involves bringing together information from two or more DataFrames based on a common key or index. This is particularly useful when dealing with related datasets or when you want to integrate information from multiple sources.\n",
                "\n",
                "#### Scenarios for DataFrame Combination:\n",
                "\n",
                "1. **Data Integration:**\n",
                "   - Combine datasets with shared information to create a unified view.\n",
                "\n",
                "2. **Relational Databases:**\n",
                "   - Mimic relational database joins for complex data relationships.\n",
                "\n",
                "3. **Time Series Alignment:**\n",
                "   - Align datasets based on time indices for time series analysis.\n",
                "\n",
                "4. **Handling Missing Data:**\n",
                "   - Fill in missing information by combining datasets with complementary information."
            ],
            "metadata": {
                "azdata_cell_guid": "81bdb1c8-617b-4cb8-bc42-788285183aa2"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Types of Merges:\n",
                "\n",
                "##### 1. Inner Merge:"
            ],
            "metadata": {
                "azdata_cell_guid": "c03993b1-5935-4175-9a3b-8b5a52e9dff7"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Sample DataFrames\n",
                "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['laxman', 'harshita', 'naina']})\n",
                "df2 = pd.DataFrame({'ID': [2, 3, 4], 'Salary': [60000, 45000, 70000]})\n",
                "\n",
                "# Inner Merge on 'ID'\n",
                "merged_inner = pd.merge(df1, df2, on='ID', how='inner')\n",
                "\n",
                "# Displaying the merged DataFrame\n",
                "print(\"Inner Merge Result:\")\n",
                "print(merged_inner)\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "ec1b8c77-0fc9-4a3d-8d7f-804ca6ca6b34",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Inner Merge Result:\n   ID      Name  Salary\n0   2  harshita   60000\n1   3     naina   45000\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": [
                "- **Result:**\n",
                "  - Only rows with common 'ID' values in both DataFrames are retained."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "ff2bda2e-e678-4044-9f29-ebf6f2b06799"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "##### 2. Outer Merge:"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "9eb147c8-8dda-4435-a6de-07f2205c263b"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Outer Merge on 'ID'\n",
                "merged_outer = pd.merge(df1, df2, on='ID', how='outer')\n",
                "\n",
                "# Displaying the merged DataFrame\n",
                "print(\"\\nOuter Merge Result:\")\n",
                "print(merged_outer)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "18fc846d-0a8d-4c4d-8b42-cdd13914036d"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nOuter Merge Result:\n   ID     Name   Salary\n0   1    Alice      NaN\n1   2      Bob  60000.0\n2   3  Charlie  45000.0\n3   4      NaN  70000.0\n"
                }
            ],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "- **Result:**\n",
                "  - All rows from both DataFrames are included. NaN is used for missing values."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "5de20d0f-5417-4c6c-b4e6-a72ec8c688e2"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "##### 3. Left Merge:"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "1c605668-7183-4e64-bcd5-ea0f354b4a39"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Left Merge on 'ID'\n",
                "merged_left = pd.merge(df1, df2, on='ID', how='left')\n",
                "\n",
                "# Displaying the merged DataFrame\n",
                "print(\"\\nLeft Merge Result:\")\n",
                "print(merged_left)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "80378d7e-303f-4fed-8f69-2ed3a4090dc0"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nLeft Merge Result:\n   ID     Name   Salary\n0   1    Alice      NaN\n1   2      Bob  60000.0\n2   3  Charlie  45000.0\n"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "- **Result:**\n",
                "  - All rows from the left DataFrame (df1) are retained. NaN for missing values in the right DataFrame."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "baacb584-7965-4c18-be15-4ae643f7c5bc"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "##### 4. Right Merge:"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "95638341-ccc9-44c6-b8dd-b9b6a4d558d3"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Right Merge on 'ID'\n",
                "merged_right = pd.merge(df1, df2, on='ID', how='right')\n",
                "\n",
                "# Displaying the merged DataFrame\n",
                "print(\"\\nRight Merge Result:\")\n",
                "print(merged_right)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "317aa458-a327-4cee-9fc4-f9ec317d4a04"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nRight Merge Result:\n   ID     Name  Salary\n0   2      Bob   60000\n1   3  Charlie   45000\n2   4      NaN   70000\n"
                }
            ],
            "execution_count": 4
        },
        {
            "cell_type": "markdown",
            "source": [
                "- **Result:**\n",
                "  - All rows from the right DataFrame (df2) are retained. NaN for missing values in the left DataFrame."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "c3794f1e-76b8-4236-9488-41627050291d"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Implications of Merge Types:\n",
                "\n",
                "- **Inner Merge:**\n",
                "  - Retains only rows with matching keys in both DataFrames.\n",
                "\n",
                "- **Outer Merge:**\n",
                "  - Retains all rows from both DataFrames, filling in missing values with NaN.\n",
                "\n",
                "- **Left Merge:**\n",
                "  - Retains all rows from the left DataFrame, filling in missing values with NaN.\n",
                "\n",
                "- **Right Merge:**\n",
                "  - Retains all rows from the right DataFrame, filling in missing values with NaN.\n",
                "\n",
                "#### Considerations:\n",
                "\n",
                "- **Key Column(s):**\n",
                "  - Specify the key column(s) on which to merge the DataFrames.\n",
                "\n",
                "- **Duplicate Keys:**\n",
                "  - Be cautious about duplicate keys; they can result in unexpected behavior.\n",
                "\n",
                "- **Multiple Key Columns:**\n",
                "  - Merge on multiple columns for more complex relationships.\n",
                "\n",
                "#### Tips:\n",
                "\n",
                "- **Suffixes:**\n",
                "  - Use `suffixes` parameter to differentiate columns with the same name in the merged DataFrames.\n",
                "\n",
                "- **Index-Based Merge:**\n",
                "  - Merge based on indices using `left_index` and `right_index` parameters.\n",
                "\n",
                "Merging DataFrames is a crucial aspect of data manipulation in Pandas, enabling the combination of information from diverse sources. Understanding the types of merges and their implications empowers efficient data integration and analysis."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "9a2f416e-6222-4efb-930c-83c09d7224de"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### **`Concatenation and Merging Operations in Pandas`**"
            ],
            "metadata": {
                "azdata_cell_guid": "7115ac90-33ed-4269-b976-cc7c9c70baad"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Concatenation with `concat()`:\n",
                "\n",
                "Concatenation in Pandas involves combining DataFrames either vertically or horizontally.\n",
                "\n",
                "##### 1. Vertical Concatenation:"
            ],
            "metadata": {
                "azdata_cell_guid": "9ff03907-dd34-4adf-a3c0-8ab856c0d33e"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Sample DataFrames\n",
                "df1 = pd.DataFrame({'A': ['A0', 'A1'], 'B': ['B0', 'B1']})\n",
                "df2 = pd.DataFrame({'A': ['A2', 'A3'], 'B': ['B2', 'B3']})\n",
                "\n",
                "# Vertical Concatenation\n",
                "concatenated_vertical = pd.concat([df1, df2])\n",
                "\n",
                "# Displaying the concatenated DataFrame\n",
                "print(\"Vertical Concatenation Result:\")\n",
                "print(concatenated_vertical)"
            ],
            "metadata": {
                "azdata_cell_guid": "a3c09e05-d0e9-4fb7-a0db-01a55c21918e",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Vertical Concatenation Result:\n    A   B\n0  A0  B0\n1  A1  B1\n0  A2  B2\n1  A3  B3\n"
                }
            ],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "- **Result:**\n",
                "  - Rows from both DataFrames are stacked vertically."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "081036df-4898-4ce6-90e7-b651887e045e"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "##### 2. Horizontal Concatenation:"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "8a8c70f3-919a-4f80-a8bd-d9e355b305af"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Sample DataFrames\n",
                "df3 = pd.DataFrame({'C': ['C0', 'C1'], 'D': ['D0', 'D1']})\n",
                "\n",
                "# Horizontal Concatenation\n",
                "concatenated_horizontal = pd.concat([df1, df3], axis=1)\n",
                "\n",
                "# Displaying the concatenated DataFrame\n",
                "print(\"\\nHorizontal Concatenation Result:\")\n",
                "print(concatenated_horizontal)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "3bc8644d-c79e-4720-86f5-c08c7a2c78d3"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nHorizontal Concatenation Result:\n    A   B   C   D\n0  A0  B0  C0  D0\n1  A1  B1  C1  D1\n"
                }
            ],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": [
                "- **Result:**\n",
                "  - Columns from both DataFrames are joined horizontally."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "1e1a0f55-8c13-4f26-bf62-747a3b4c22d9"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Merging with `merge()`:\n",
                "\n",
                "The `merge()` function combines DataFrames based on specified columns."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "375e7c6a-823a-4af9-b998-2dc231e26cee"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Sample DataFrames\n",
                "df4 = pd.DataFrame({'ID': [1, 2], 'Name': ['Alice', 'Bob']})\n",
                "df5 = pd.DataFrame({'ID': [2, 3], 'Salary': [60000, 45000]})\n",
                "\n",
                "# Merging on 'ID'\n",
                "merged_result = pd.merge(df4, df5, on='ID', how='inner')\n",
                "\n",
                "# Displaying the merged DataFrame\n",
                "print(\"\\nMerge Result:\")\n",
                "print(merged_result)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "3dcb1158-1a23-498d-97b2-31c9dfcb02ca"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nMerge Result:\n   ID Name  Salary\n0   2  Bob   60000\n"
                }
            ],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": [
                "- **Result:**\n",
                "  - Inner merge on 'ID' retains only rows with common 'ID' values."
            ],
            "metadata": {
                "azdata_cell_guid": "b9f89a43-93a4-4df7-b80f-9c28b8a1754a"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Merging Parameters:\n",
                "\n",
                "- **`how`:**\n",
                "  - Specifies the type of merge (e.g., 'inner', 'outer', 'left', 'right').\n",
                "\n",
                "- **`on`:**\n",
                "  - Specifies the key column(s) for merging.\n",
                "\n",
                "- **`suffixes`:**\n",
                "  - Appends suffixes to duplicate column names in case of overlap.\n",
                "\n",
                "#### Considerations:\n",
                "\n",
                "- **Common Key Columns:**\n",
                "  - Ensure the key columns have the same name and contain common values.\n",
                "\n",
                "- **Duplicate Columns:**\n",
                "  - Be cautious about duplicate columns; use `suffixes` to handle them.\n",
                "\n",
                "#### Tips:\n",
                "\n",
                "- **Multiple Key Columns:**\n",
                "  - Merge on multiple columns for complex relationships using a list in the `on` parameter.\n",
                "\n",
                "- **Index-Based Merge:**\n",
                "  - Merge based on indices using `left_index` and `right_index` parameters.\n",
                "\n",
                "Combining DataFrames using `concat()` and `merge()` provides flexibility in managing and integrating data. Understanding these functions and their parameters allows for efficient data manipulation and analysis in various scenarios.\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "8445d6e1-830d-4b1f-80af-aee3716c674c"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **`11. Reshaping Data`**"
            ],
            "metadata": {
                "azdata_cell_guid": "30c07ebf-d6ff-4c0d-ac63-2488173a15ce"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### **`Pivoting and Melting in Pandas for Data Reshaping`**"
            ],
            "metadata": {
                "azdata_cell_guid": "dd79bfd3-1f45-42f2-bacb-1a0f3f707215"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Pivoting in Pandas:\n",
                "\n",
                "Pivoting involves reshaping data to rearrange or reshape the structure of the DataFrame, typically by changing the layout of data in the columns."
            ],
            "metadata": {
                "azdata_cell_guid": "cae89c73-1b3d-42ea-8721-9d7485b2a401"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Sample DataFrame\n",
                "data = {'Date': ['2022-01-01', '2022-01-01', '2022-01-02', '2022-01-02'],\n",
                "        'Category': ['A', 'B', 'A', 'B'],\n",
                "        'Value': [10, 20, 30, 40]}\n",
                "\n",
                "df = pd.DataFrame(data)\n",
                "\n",
                "# Pivoting DataFrame\n",
                "pivot_result = df.pivot(index='Date', columns='Category', values='Value')\n",
                "\n",
                "# Displaying the pivoted DataFrame\n",
                "print(\"Pivoted DataFrame:\")\n",
                "print(pivot_result)\n",
                "\n",
                "# Result - Rows with the same 'Date' are combined, and 'Category' values become separate columns."
            ],
            "metadata": {
                "azdata_cell_guid": "440da13a-28c7-4928-a269-0a597d8d97be",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Pivoted DataFrame:\nCategory     A   B\nDate              \n2022-01-01  10  20\n2022-01-02  30  40\n"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Melting in Pandas:\n",
                "\n",
                "Melting involves transforming a DataFrame from wide format to long format, unpivoting it."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "5796eb7f-adbe-4d9e-8de5-224a123c4cdf"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Melting DataFrame\n",
                "melted_result = pd.melt(df, id_vars='Date', value_vars='Value', var_name='Category', value_name='Value')\n",
                "\n",
                "# Displaying the melted DataFrame\n",
                "print(\"\\nMelted DataFrame:\")\n",
                "print(melted_result)\n",
                "\n",
                "# Result:\n",
                "# Columns 'A' and 'B' from the previous DataFrame become rows, with a new 'Category' column."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "93438b54-40ac-4c3a-89c4-da69611106bb"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nMelted DataFrame:\n         Date Category  Value\n0  2022-01-01    Value     10\n1  2022-01-01    Value     20\n2  2022-01-02    Value     30\n3  2022-01-02    Value     40\n"
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": "<ipython-input-10-7de399574c56>:2: FutureWarning: This dataframe has a column name that matches the 'value_name' column name of the resulting Dataframe. In the future this will raise an error, please set the 'value_name' parameter of DataFrame.melt to a unique name.\n  melted_result = pd.melt(df, id_vars='Date', value_vars='Value', var_name='Category', value_name='Value')\n"
                }
            ],
            "execution_count": 10
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Applications:\n",
                "\n",
                "- **Pivoting:**\n",
                "  - Convert data for better presentation or visualization.\n",
                "  - Facilitate analysis by organizing data for specific requirements.\n",
                "\n",
                "- **Melting:**\n",
                "  - Convert aggregated or summarized data into a long format.\n",
                "  - Prepare data for specific analyses or visualizations.\n",
                "\n",
                "#### Use Cases:\n",
                "\n",
                "1. **Pivoting Example:**\n",
                "   - Convert sales data with columns for each product category into a format where each row represents a sale with product category and quantity.\n",
                "\n",
                "2. **Melting Example:**\n",
                "   - Transform a DataFrame with a multi-level column index into a long format for easier analysis.\n",
                "\n",
                "#### Considerations:\n",
                "\n",
                "- **Unique Index Values:**\n",
                "  - Ensure that the combination of index and columns in a pivoted DataFrame results in unique index values.\n",
                "\n",
                "- **Melting Wide Data:**\n",
                "  - Specify columns to be preserved as identifier variables and those to be melted.\n",
                "\n",
                "#### Tips:\n",
                "\n",
                "- **Multi-level Index:**\n",
                "  - When pivoting, use `reset_index()` if the DataFrame has a multi-level index.\n",
                "\n",
                "- **Handling NaN Values:**\n",
                "  - Check for NaN values after pivoting, especially if using hierarchical indexing.\n",
                "\n",
                "Pivoting and melting are powerful tools in reshaping data to meet specific analysis or visualization needs. Mastering these operations allows for efficient manipulation and exploration of diverse datasets in Pandas.\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "9f07c2eb-1d5b-4754-a6e4-0cb469a29c55"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### **`Stacking and Unstacking in Pandas for Hierarchical Index Reshaping`**"
            ],
            "metadata": {
                "azdata_cell_guid": "14dd8f6d-95d5-44c3-8716-b89995e25bba"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Stacking and Unstacking Concepts:\n",
                "\n",
                "In Pandas, stacking and unstacking are operations used to manipulate DataFrames with hierarchical index structures, particularly those with multi-level indices.\n",
                "\n",
                "#### Stacking:\n",
                "\n",
                "Stacking involves \"compressing\" a level in the DataFrame's columns to produce a new level in the index."
            ],
            "metadata": {
                "azdata_cell_guid": "174d882b-5e6d-4b73-8048-9486517477b0"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Sample DataFrame with Multi-level Index\n",
                "arrays = [['A', 'A', 'B', 'B'], [1, 2, 1, 2]]\n",
                "index = pd.MultiIndex.from_arrays(arrays, names=('Letter', 'Number'))\n",
                "\n",
                "df = pd.DataFrame({'Value': [10, 20, 30, 40]}, index=index)\n",
                "\n",
                "# Stacking DataFrame\n",
                "stacked_result = df.stack()\n",
                "\n",
                "# Displaying the stacked DataFrame\n",
                "print(\"Stacked DataFrame:\")\n",
                "print(stacked_result)\n",
                "\n",
                "# Result:\n",
                "# The DataFrame is compressed, and a new level is created in the index."
            ],
            "metadata": {
                "azdata_cell_guid": "4d41e607-2e8c-45f2-8fc2-a6b8b2dbac64",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Stacked DataFrame:\nLetter  Number       \nA       1       Value    10\n        2       Value    20\nB       1       Value    30\n        2       Value    40\ndtype: int64\n"
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Unstacking:\n",
                "\n",
                "Unstacking is the inverse operation of stacking. It involves \"expanding\" a level in the DataFrame's index to produce a new level in the columns."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "df3c3aae-6bfa-44b6-aad8-aad8ef57c13b"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Unstacking DataFrame\n",
                "unstacked_result = df.unstack()\n",
                "\n",
                "# Displaying the unstacked DataFrame\n",
                "print(\"\\nUnstacked DataFrame:\")\n",
                "print(unstacked_result)\n",
                "\n",
                "# Result : The DataFrame is expanded, and a new level is created in the columns."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "19d9d43c-a3d0-4958-8c62-1c9bb78aeb3e"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nUnstacked DataFrame:\n       Value    \nNumber     1   2\nLetter          \nA         10  20\nB         30  40\n"
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Applications:\n",
                "\n",
                "- **Stacking:**\n",
                "  - Transform a DataFrame with a multi-level column index into a long format.\n",
                "  - Facilitate analysis or visualization requiring a simpler column structure.\n",
                "\n",
                "- **Unstacking:**\n",
                "  - Convert data with a multi-level index into a wide format for better presentation.\n",
                "  - Facilitate analysis by organizing data in a way that simplifies access to information.\n",
                "\n",
                "#### Use Cases:\n",
                "\n",
                "1. **Stacking Example:**\n",
                "   - Convert sales data with a multi-level column index (products, regions) into a long format for easy analysis.\n",
                "\n",
                "2. **Unstacking Example:**\n",
                "   - Transform a DataFrame with a multi-level index representing time series data into a wide format with columns for each time point.\n",
                "\n",
                "#### Considerations:\n",
                "\n",
                "- **Level Selection:**\n",
                "  - Specify the level to be stacked or unstacked.\n",
                "\n",
                "- **NaN Values:**\n",
                "  - Check for NaN values after unstacking, especially if the original DataFrame had missing data.\n",
                "\n",
                "#### Tips:\n",
                "\n",
                "- **Multiple Levels:**\n",
                "  - Stack or unstack multiple levels by passing a list of level names or level numbers.\n",
                "\n",
                "- **Naming Levels:**\n",
                "  - Assign names to levels for clarity using the `names` parameter in `MultiIndex`.\n",
                "\n",
                "Stacking and unstacking are essential operations for reshaping hierarchical index structures in Pandas. Understanding when and how to use these operations allows for efficient manipulation and exploration of multi-level index DataFrames.\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "88858cf1-74fd-4c20-9739-c8f5ddf2590b"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **`12. Time Series Data`**"
            ],
            "metadata": {
                "azdata_cell_guid": "581fcd51-e5c6-494f-a923-a03a3e57ceab"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **`Handling Time and Date Data in Pandas`**"
            ],
            "metadata": {
                "azdata_cell_guid": "93e0d834-986a-45c2-9d8e-5e40bd0bc0f1"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Importance of Handling Time and Date Data:\n",
                "\n",
                "Handling time and date data is crucial in data analysis for various reasons:\n",
                "\n",
                "1. **Temporal Analysis:**\n",
                "   - Time-based insights, trends, and patterns are essential for understanding data.\n",
                "\n",
                "2. **Time Series Analysis:**\n",
                "   - Analyzing data collected over time for forecasting and trend identification.\n",
                "\n",
                "3. **Data Alignment:**\n",
                "   - Aligning datasets based on time indices for effective merging and analysis.\n",
                "\n",
                "4. **Event Sequencing:**\n",
                "   - Understanding the chronological order of events for context-aware analysis.\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "ef707a6b-0f04-424e-b5cf-e8f2407d7994"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### `DatetimeIndex` in Pandas:\n",
                "\n",
                "Pandas provides the `DatetimeIndex`, a powerful tool for working with time and date data."
            ],
            "metadata": {
                "azdata_cell_guid": "1fb97e57-2e05-4257-a8ad-f068627e7dbb"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Creating a DatetimeIndex\n",
                "date_rng = pd.date_range(start='2022-01-01', end='2022-01-10', freq='D')\n",
                "\n",
                "# Creating a DataFrame with DatetimeIndex\n",
                "df = pd.DataFrame(date_rng, columns=['date'])\n",
                "\n",
                "# Displaying the DataFrame\n",
                "print(\"DataFrame with DatetimeIndex:\")\n",
                "print(df)\n",
                "\n",
                "# Result :  The DataFrame contains a `DatetimeIndex` ranging from '2022-01-01' to '2022-01-10'.\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "c939f166-ddcb-4fe8-ab79-81e2943a00fa",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "DataFrame with DatetimeIndex:\n        date\n0 2022-01-01\n1 2022-01-02\n2 2022-01-03\n3 2022-01-04\n4 2022-01-05\n5 2022-01-06\n6 2022-01-07\n7 2022-01-08\n8 2022-01-09\n9 2022-01-10\n"
                }
            ],
            "execution_count": 13
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Manipulating Time Series Data:"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "f91c3a2d-5b05-4b04-9ed4-35e296492817"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Adding a new column with random values\n",
                "import numpy as np\n",
                "\n",
                "df['value'] = np.random.randint(0, 100, size=(len(date_rng)))\n",
                "\n",
                "# Displaying the updated DataFrame\n",
                "print(\"\\nDataFrame with Random Values:\")\n",
                "print(df)\n",
                "\n",
                "# Result : The DataFrame now includes a 'value' column with random integer values."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "27c26d77-6ce4-4391-b751-e7ff4c905405"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nDataFrame with Random Values:\n        date  value\n0 2022-01-01     64\n1 2022-01-02     62\n2 2022-01-03     91\n3 2022-01-04     30\n4 2022-01-05     52\n5 2022-01-06     66\n6 2022-01-07     60\n7 2022-01-08      7\n8 2022-01-09     19\n9 2022-01-10     69\n"
                }
            ],
            "execution_count": 14
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Time Series Operations:"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "59f481b6-19ba-43e9-9800-e8e9cac7a14b"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Extracting components of the date\n",
                "df['year'] = df['date'].dt.year\n",
                "df['month'] = df['date'].dt.month\n",
                "df['day'] = df['date'].dt.day\n",
                "df['weekday'] = df['date'].dt.day_name()\n",
                "\n",
                "# Displaying the DataFrame with extracted components\n",
                "print(\"\\nDataFrame with Date Components:\")\n",
                "print(df)\n",
                "\n",
                "# Result : Additional columns are added for the year, month, day, and weekday of each date."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "f4448087-f423-4d66-b85f-18de8b82a267"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nDataFrame with Date Components:\n        date  value  year  month  day    weekday\n0 2022-01-01     64  2022      1    1   Saturday\n1 2022-01-02     62  2022      1    2     Sunday\n2 2022-01-03     91  2022      1    3     Monday\n3 2022-01-04     30  2022      1    4    Tuesday\n4 2022-01-05     52  2022      1    5  Wednesday\n5 2022-01-06     66  2022      1    6   Thursday\n6 2022-01-07     60  2022      1    7     Friday\n7 2022-01-08      7  2022      1    8   Saturday\n8 2022-01-09     19  2022      1    9     Sunday\n9 2022-01-10     69  2022      1   10     Monday\n"
                }
            ],
            "execution_count": 16
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Time Resampling:"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "c9777cbe-d0c6-4168-aa66-747ab1b481d1"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Resampling the DataFrame to weekly frequency\n",
                "weekly_df = df.resample('W-Mon', on='date').sum()\n",
                "\n",
                "# Displaying the resampled DataFrame\n",
                "print(\"\\nResampled DataFrame (Weekly):\")\n",
                "print(weekly_df)\n",
                "\n",
                "# Result : The DataFrame is resampled to a weekly frequency, aggregating values based on the sum."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "2242112d-19fd-4d99-829d-e789db955710"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nResampled DataFrame (Weekly):\n            value   year  month  day\ndate                                \n2022-01-03    217   6066      3    6\n2022-01-10    303  14154      7   49\n"
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": "<ipython-input-17-28915bc88b0e>:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  weekly_df = df.resample('W-Mon', on='date').sum()\n"
                }
            ],
            "execution_count": 17
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Considerations:\n",
                "\n",
                "- **Date Components:**\n",
                "  - Extracting date components facilitates detailed analysis and reporting.\n",
                "\n",
                "- **Resampling Frequency:**\n",
                "  - Choose the appropriate frequency when resampling data to suit analysis requirements.\n",
                "\n",
                "#### Tips:\n",
                "\n",
                "- **Time Zone Handling:**\n",
                "  - Consider time zone information when working with data from different regions.\n",
                "\n",
                "- **Periods and Durations:**\n",
                "  - Explore Pandas' `Period` and `Timedelta` for handling periods and durations.\n",
                "\n",
                "Handling time and date data with Pandas' `DatetimeIndex` enables effective analysis, visualization, and manipulation of time series data. Leveraging these functionalities enhances the ability to derive meaningful insights from datasets with temporal components.\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "a91e5021-d393-4535-a162-c47c3c867358"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **`Resampling and Frequency Conversion in Pandas`**"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "5a98e6f4-4619-43af-9e8b-cc4afeef07a1"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Resampling and Frequency Conversion Concepts:\n",
                "\n",
                "Resampling involves changing the frequency of time series data, either increasing or decreasing the frequency, to suit analysis or visualization needs. It is a crucial operation in time series analysis.\n",
                "\n",
                "#### Using `resample()` in Pandas:\n",
                "\n",
                "The `resample()` function in Pandas allows for flexible and powerful resampling of time series data."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "220d5ae3-f3f5-4ea1-acfd-e55d28039ac9"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Sample DataFrame with DatetimeIndex\n",
                "date_rng = pd.date_range(start='2022-01-01', end='2022-01-10', freq='D')\n",
                "df = pd.DataFrame(date_rng, columns=['date'])\n",
                "df['value'] = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
                "\n",
                "# Resampling to weekly frequency\n",
                "weekly_df = df.resample('W-Mon', on='date').sum()\n",
                "\n",
                "# Displaying the resampled DataFrame\n",
                "print(\"Resampled DataFrame (Weekly):\")\n",
                "print(weekly_df)\n",
                "\n",
                "# Result : The DataFrame is resampled to a weekly frequency (every Monday), and the values are summed for each week.\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "17394feb-7c5d-4dd5-b20d-fe1a938d3243"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Resampled DataFrame (Weekly):\n            value\ndate             \n2022-01-03     60\n2022-01-10    490\n"
                }
            ],
            "execution_count": 18
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Handling Missing Values during Resampling:"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "569cb33d-57f9-4456-bf08-a44afb220ece"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Adding some missing values to the DataFrame\n",
                "df.loc[df['date'] == '2022-01-03', 'value'] = None\n",
                "df.loc[df['date'] == '2022-01-07', 'value'] = None\n",
                "\n",
                "# Resampling with handling missing values using forward fill (ffill)\n",
                "resampled_filled = df.resample('D', on='date').sum().ffill()\n",
                "\n",
                "# Displaying the resampled and filled DataFrame\n",
                "print(\"\\nResampled DataFrame with Forward Fill for Missing Values:\")\n",
                "print(resampled_filled)\n",
                "\n",
                "# Result : Missing values are filled using forward fill (`ffill`) during the resampling process."
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "7a7bd112-b41e-4d22-9396-b7617da553d1"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\nResampled DataFrame with Forward Fill for Missing Values:\n            value\ndate             \n2022-01-01   10.0\n2022-01-02   20.0\n2022-01-03    0.0\n2022-01-04   40.0\n2022-01-05   50.0\n2022-01-06   60.0\n2022-01-07    0.0\n2022-01-08   80.0\n2022-01-09   90.0\n2022-01-10  100.0\n"
                }
            ],
            "execution_count": 19
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Applications:\n",
                "\n",
                "- **Aggregating Data:**\n",
                "  - Summarize data over larger time intervals for higher-level insights.\n",
                "\n",
                "- **Handling Missing Values:**\n",
                "  - Address missing values during resampling using methods like forward fill or interpolation.\n",
                "\n",
                "#### Considerations:\n",
                "\n",
                "- **Resampling Rule:**\n",
                "  - Choose the appropriate resampling rule ('D' for day, 'W' for week, etc.) based on analysis requirements.\n",
                "\n",
                "- **Handling Missing Values:**\n",
                "  - Consider the method for handling missing values during resampling, such as forward fill, backward fill, or interpolation.\n",
                "\n",
                "#### Tips:\n",
                "\n",
                "- **Custom Resampling Rules:**\n",
                "  - Create custom resampling rules to fit specific business requirements.\n",
                "\n",
                "- **Chaining Operations:**\n",
                "  - Chain operations like resampling and aggregations for more complex analysis.\n",
                "\n",
                "Resampling and frequency conversion in Pandas are powerful techniques for adjusting the temporal granularity of time series data. These operations facilitate meaningful analysis and visualization, ensuring that the data aligns with the desired temporal context.\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "2a36f169-5ec1-4ecb-a75d-9f540f843ae5"
            },
            "attachments": {}
        }
    ]
}