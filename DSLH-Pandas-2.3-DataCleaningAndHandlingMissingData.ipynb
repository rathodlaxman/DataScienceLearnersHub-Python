{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# **`Data Science Learners Hub`**\n",
                "\n",
                "**Module : Python**\n",
                "\n",
                "**email** : [datasciencelearnershub@gmail.com](mailto:datasciencelearnershub@gmail.com)"
            ],
            "metadata": {
                "azdata_cell_guid": "20047c27-4352-4d28-8b98-9ea8c8a5dc18"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **`#2: DataFrames in Depth`**\n",
                "4. **Creating DataFrames**\n",
                "   - From lists, dictionaries, and arrays\n",
                "   - Reading data from CSV, Excel, and other formats\n",
                "\n",
                "5. **Basic DataFrame Operations**\n",
                "   - Inspecting the DataFrame\n",
                "   - Indexing and selecting data\n",
                "   - Descriptive statistics\n",
                "\n",
                "6. **Data Cleaning and Handling Missing Data**\n",
                "   - Handling missing values\n",
                "   - Dropping or filling missing values\n",
                "   - Removing duplicates"
            ],
            "metadata": {
                "azdata_cell_guid": "e472e1b9-9386-49b9-b3e0-cfadc75ea05d"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **`6. Data Cleaning and Handling Missing Data`**"
            ],
            "metadata": {
                "azdata_cell_guid": "fab16289-0f90-459b-a14e-56212ef4af3e"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### **`Handling Missing Values`**"
            ],
            "metadata": {
                "azdata_cell_guid": "b83e0605-c8f0-4ac1-94b1-bff25dc3d8bc"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Importance of Identifying and Handling Missing Values in a DataFrame:\n",
                "\n",
                "Missing values, represented as NaN (Not a Number) in Pandas, are a common occurrence in real-world datasets. Properly identifying and handling missing values is crucial for meaningful and accurate data analysis. Ignoring missing values can lead to biased results and incorrect interpretations. Here's why handling missing values is important:\n",
                "\n",
                "1. **Data Accuracy:** Missing values can distort summary statistics, such as mean and standard deviation, leading to inaccurate insights about the dataset.\n",
                "\n",
                "2. **Model Performance:** If missing values are not addressed, they can adversely impact machine learning models, causing biased predictions and reduced model performance.\n",
                "\n",
                "3. **Data Visualization:** Visualizations may not accurately represent the distribution of data when missing values are present, affecting the interpretation of results.\n",
                "\n",
                "4. **Statistical Analyses:** Many statistical analyses and tests assume complete data. Missing values can compromise the validity of statistical results and significance testing."
            ],
            "metadata": {
                "azdata_cell_guid": "fc8004d5-7f2d-4608-ac60-999bf122f694"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Methods for Handling Missing Values:\n",
                "\n",
                "1. **Identifying Missing Values:**\n",
                "   - **`isna()` and `notna()`:**"
            ],
            "metadata": {
                "azdata_cell_guid": "86611650-a1f3-4ba2-a04c-8e7c239db9ee"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Creating a DataFrame with missing values\n",
                "data = {\n",
                "    'A': [1, 2, np.nan, 4, 5, 6, 7],\n",
                "    'B': [5, np.nan, 7, 8, np.nan, 10, 11],\n",
                "    'C': [9, 10, 11, np.nan, 13, 14, 15],\n",
                "    'D': [14, np.nan, 16, 17, 18, np.nan, 20],\n",
                "}\n",
                "\n",
                "# Adding more rows to the DataFrame\n",
                "for i in range(5):\n",
                "    data['A'].append(np.nan)\n",
                "    data['B'].append(np.random.randint(1, 100))  # Random integers as additional values\n",
                "    data['C'].append(np.random.choice(['apple', 'banana', 'orange']))  # Random strings as additional values\n",
                "    data['D'].append(np.random.uniform(0, 1))  # Random floats as additional values\n",
                "\n",
                "df = pd.DataFrame(data)\n",
                "\n",
                "# Display the DataFrame\n",
                "print(\"Original DataFrame:\")\n",
                "print(df)\n",
                "\n",
                "# Check for missing values\n",
                "missing_values = df.isna()\n",
                "not_missing_values = df.notna()\n",
                "\n",
                "# Display the DataFrames with True for missing values\n",
                "print(\"\\nDataFrame with True for Missing Values:\")\n",
                "print(missing_values)\n",
                "\n",
                "# Display the opposite DataFrame (True for non-missing values)\n",
                "print(\"\\nDataFrame with True for Non-Missing Values:\")\n",
                "print(not_missing_values)\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "81c73574-ed55-4692-b011-0621c04c3ea5",
                "language": "python"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Original DataFrame:\n      A     B       C          D\n0   1.0   5.0       9  14.000000\n1   2.0   NaN      10        NaN\n2   NaN   7.0      11  16.000000\n3   4.0   8.0     NaN  17.000000\n4   5.0   NaN      13  18.000000\n5   6.0  10.0      14        NaN\n6   7.0  11.0      15  20.000000\n7   NaN  79.0  banana   0.891187\n8   NaN  47.0  banana   0.708668\n9   NaN  73.0  orange   0.544267\n10  NaN  30.0   apple   0.052271\n11  NaN  13.0  orange   0.222462\n\nDataFrame with True for Missing Values:\n        A      B      C      D\n0   False  False  False  False\n1   False   True  False   True\n2    True  False  False  False\n3   False  False   True  False\n4   False   True  False  False\n5   False  False  False   True\n6   False  False  False  False\n7    True  False  False  False\n8    True  False  False  False\n9    True  False  False  False\n10   True  False  False  False\n11   True  False  False  False\n\nDataFrame with True for Non-Missing Values:\n        A      B      C      D\n0    True   True   True   True\n1    True  False   True  False\n2   False   True   True   True\n3    True   True  False   True\n4    True  False   True   True\n5    True   True   True  False\n6    True   True   True   True\n7   False   True   True   True\n8   False   True   True   True\n9   False   True   True   True\n10  False   True   True   True\n11  False   True   True   True\n"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### **`Handling Missing Values`**\n",
                "\n",
                "#### Importance of Identifying and Handling Missing Values in a DataFrame:\n",
                "\n",
                "Missing values, represented as NaN (Not a Number) in Pandas, are a common occurrence in real-world datasets. Properly identifying and handling missing values is crucial for meaningful and accurate data analysis. Ignoring missing values can lead to biased results and incorrect interpretations. Here's why handling missing values is important:\n",
                "\n",
                "1. **Data Accuracy:** Missing values can distort summary statistics, such as mean and standard deviation, leading to inaccurate insights about the dataset.\n",
                "\n",
                "2. **Model Performance:** If missing values are not addressed, they can adversely impact machine learning models, causing biased predictions and reduced model performance.\n",
                "\n",
                "3. **Data Visualization:** Visualizations may not accurately represent the distribution of data when missing values are present, affecting the interpretation of results.\n",
                "\n",
                "4. **Statistical Analyses:** Many statistical analyses and tests assume complete data. Missing values can compromise the validity of statistical results and significance testing.\n",
                "\n",
                "#### Methods for Handling Missing Values:\n",
                "\n",
                "1. **Identifying Missing Values:**\n",
                "   - **`isna()` and `notna()`:**\n",
                "     ```python\n",
                "     # Check for missing values\n",
                "     df.isna()  # Returns a DataFrame of the same shape with True for missing values\n",
                "     df.notna()  # Returns the opposite of isna()\n",
                "     ```\n",
                "\n",
                "2. **Handling Missing Values:**\n",
                "   - **`fillna()`:**\n",
                "     ```python\n",
                "     # Fill missing values with a specified value or a calculated value\n",
                "     df.fillna(value)  # Fill with a constant value\n",
                "     df.fillna(df.mean())  # Fill with the mean of each column\n",
                "     ```\n",
                "\n",
                "   - **Dropping Missing Values:**\n",
                "     ```python\n",
                "     # Drop rows or columns containing missing values\n",
                "     df.dropna()  # Drop rows with any missing values\n",
                "     df.dropna(axis=1)  # Drop columns with any missing values\n",
                "     ```\n",
                "\n",
                "   - **Interpolation:**\n",
                "     ```python\n",
                "     # Interpolate missing values using various methods (linear, polynomial, etc.)\n",
                "     df.interpolate()\n",
                "     ```\n",
                "\n",
                "#### Considerations and Best Practices:\n",
                "\n",
                "- **Context Matters:** The method chosen to handle missing values depends on the nature of the data and the reason for missingness. Consider the context before applying a specific strategy.\n",
                "\n",
                "- **Impact on Analysis:** Understand how the chosen method might impact your analysis. For example, filling missing values with the mean could introduce bias if missingness is not random.\n",
                "\n",
                "- **Visualization:** Visualize the distribution of missing values using tools like heatmaps to better understand patterns of missingness.\n",
                "\n",
                "- **Documentation:** Clearly document the chosen strategy for handling missing values in your analysis to ensure transparency and reproducibility.\n",
                "\n",
                "#### Conclusion:\n",
                "\n",
                "Properly handling missing values is a critical step in the data cleaning process. It ensures the integrity of analyses and models, leading to more reliable and accurate results. Familiarizing yourself with Pandas methods like `isna()`, `notna()`, and `fillna()` empowers you to make informed decisions when dealing with missing data in your DataFrame."
            ],
            "metadata": {
                "azdata_cell_guid": "bd1db635-db41-4d80-91c9-3967b49f4414"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Example:\n",
                "Consider a scenario where we have a DataFrame containing information about students' exam scores in different subjects. The dataset has missing values that need to be handled, and we'll demonstrate the use of `isna()`, `notna()`, and `fillna()` to address these missing values."
            ],
            "metadata": {
                "azdata_cell_guid": "961b1b21-5c52-4c1c-b6ff-75b859413755"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Sample student exam data with missing values\n",
                "exam_data = {\n",
                "    'StudentID': [1, 2, 3, 4, 5],\n",
                "    'Math_Score': [85, np.nan, 78, 92, 88],\n",
                "    'English_Score': [75, 85, np.nan, 88, 92],\n",
                "    'Physics_Score': [90, 78, 85, np.nan, 94],\n",
                "    'Chemistry_Score': [82, 88, 90, 76, np.nan],\n",
                "}\n",
                "\n",
                "# Creating a DataFrame from the exam data\n",
                "df_exams = pd.DataFrame(exam_data)\n",
                "\n",
                "# Displaying the original DataFrame\n",
                "print(\"Original DataFrame:\")\n",
                "print(df_exams)\n",
                "\n",
                "# Identifying missing values\n",
                "missing_values = df_exams.isna()\n",
                "print(\"\\nMissing Values:\")\n",
                "print(missing_values)\n",
                "\n",
                "# Filling missing values with the mean of each column\n",
                "mean_filled_df = df_exams.fillna(df_exams.mean())\n",
                "\n",
                "# Displaying the DataFrame after handling missing values\n",
                "print(\"\\nDataFrame after Filling Missing Values with Mean:\")\n",
                "print(mean_filled_df)\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "179aed81-2cef-4d2b-938f-f0c57e20dac7",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Original DataFrame:\n   StudentID  Math_Score  English_Score  Physics_Score  Chemistry_Score\n0          1        85.0           75.0           90.0             82.0\n1          2         NaN           85.0           78.0             88.0\n2          3        78.0            NaN           85.0             90.0\n3          4        92.0           88.0            NaN             76.0\n4          5        88.0           92.0           94.0              NaN\n\nMissing Values:\n   StudentID  Math_Score  English_Score  Physics_Score  Chemistry_Score\n0      False       False          False          False            False\n1      False        True          False          False            False\n2      False       False           True          False            False\n3      False       False          False           True            False\n4      False       False          False          False             True\n\nDataFrame after Filling Missing Values with Mean:\n   StudentID  Math_Score  English_Score  Physics_Score  Chemistry_Score\n0          1       85.00           75.0          90.00             82.0\n1          2       85.75           85.0          78.00             88.0\n2          3       78.00           85.0          85.00             90.0\n3          4       92.00           88.0          86.75             76.0\n4          5       88.00           92.0          94.00             84.0\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": [
                "In the above example:\n",
                "\n",
                "1. **Identifying Missing Values:**\n",
                "   - We use `isna()` to create a DataFrame of the same shape as the original, with `True` values where missing values are present.\n",
                "\n",
                "2. **Handling Missing Values:**\n",
                "   - We use `fillna()` to fill missing values with the mean of each column.\n",
                "\n",
                "3. **Result:**\n",
                "   - The final DataFrame (`mean_filled_df`) has missing values filled with the mean of each respective column.\n",
                "\n",
                "This example showcases the importance of identifying and handling missing values and demonstrates a practical approach using Pandas methods. Adjust the code based on your specific dataset and requirements."
            ],
            "metadata": {
                "azdata_cell_guid": "1fbb9574-65ae-4491-94ed-28aa5dbc9b9f"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Real-world Scenario:\n",
                "Consider a scenario where you have a dataset containing information about customer orders in an e-commerce platform. The dataset includes order IDs, product names, quantities, prices, and shipping dates. Due to various reasons such as system glitches or customer actions, some data is missing. Let's explore how to identify and handle missing values in this context."
            ],
            "metadata": {
                "azdata_cell_guid": "0da2795a-1df1-4f67-9cef-3f9dbc714b75"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Sample e-commerce order data with missing values\n",
                "order_data = {\n",
                "    'OrderID': [101, 102, np.nan, 104, 105],\n",
                "    'Product': ['Laptop', 'Smartphone', 'Tablet', np.nan, 'Camera'],\n",
                "    'Quantity': [2, 1, np.nan, 2, 1],\n",
                "    'Price': [1200, 800, 300, np.nan, 700],\n",
                "    'Shipping_Date': ['2022-01-01', '2022-01-02', np.nan, '2022-01-03', '2022-01-03'],\n",
                "}\n",
                "\n",
                "# Creating a DataFrame from the order data\n",
                "df_orders = pd.DataFrame(order_data)\n",
                "\n",
                "# Displaying the original DataFrame\n",
                "print(\"Original Order DataFrame:\")\n",
                "print(df_orders)\n",
                "\n",
                "# Identifying missing values\n",
                "missing_values = df_orders.isna()\n",
                "print(\"\\nMissing Values:\")\n",
                "print(missing_values)\n",
                "\n",
                "# Handling missing values by dropping rows with missing OrderID and filling Price and Shipping_Date\n",
                "df_orders_cleaned = df_orders.dropna(subset=['OrderID']).fillna({'Price': df_orders['Price'].mean(), 'Shipping_Date': '2022-01-01'})\n",
                "\n",
                "# Displaying the DataFrame after handling missing values\n",
                "print(\"\\nDataFrame after Handling Missing Values:\")\n",
                "print(df_orders_cleaned)\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "abe86a01-a02e-4e6a-9824-12a1c9588212",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Original Order DataFrame:\n   OrderID     Product  Quantity   Price Shipping_Date\n0    101.0      Laptop       2.0  1200.0    2022-01-01\n1    102.0  Smartphone       1.0   800.0    2022-01-02\n2      NaN      Tablet       NaN   300.0           NaN\n3    104.0         NaN       2.0     NaN    2022-01-03\n4    105.0      Camera       1.0   700.0    2022-01-03\n\nMissing Values:\n   OrderID  Product  Quantity  Price  Shipping_Date\n0    False    False     False  False          False\n1    False    False     False  False          False\n2     True    False      True  False           True\n3    False     True     False   True          False\n4    False    False     False  False          False\n\nDataFrame after Handling Missing Values:\n   OrderID     Product  Quantity   Price Shipping_Date\n0    101.0      Laptop       2.0  1200.0    2022-01-01\n1    102.0  Smartphone       1.0   800.0    2022-01-02\n3    104.0         NaN       2.0   750.0    2022-01-03\n4    105.0      Camera       1.0   700.0    2022-01-03\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Considerations or Peculiarities:\n",
                "\n",
                "- **Reasons for Missingness:**\n",
                "  - Understand the reasons for missing values. In this example, missing OrderID might be due to a system error, missing Product might be due to a new product without details, and missing Price and Shipping_Date might be due to incomplete data.\n",
                "\n",
                "- **Impact on Analysis:**\n",
                "  - Consider how missing values might impact your analysis. Dropping rows or filling missing values should align with the analysis goals.\n",
                "\n",
                "- **Domain Knowledge:**\n",
                "  - Domain knowledge is crucial for deciding how to handle missing values appropriately. For example, filling a missing Price with the mean might not be suitable if prices vary significantly.\n",
                "\n",
                "#### Common Mistakes:\n",
                "\n",
                "- **Ignoring Missing Values:**\n",
                "  - Ignoring missing values without assessing their impact on analyses can lead to biased results.\n",
                "\n",
                "- **Unintended Dropping:**\n",
                "  - Unintentionally dropping rows or columns without considering the reasons for missingness may result in data loss and incomplete analyses.\n",
                "\n",
                "- **Inconsistent Handling:**\n",
                "  - Inconsistently handling missing values across different columns or datasets can introduce inconsistencies in your analysis.\n",
                "\n",
                "Handling missing values requires careful consideration and should be aligned with the overall data analysis goals. It's essential to understand the dataset's context and choose appropriate strategies based on the nature of the missing data.\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "d90c9d6c-91af-42d9-9bc4-0ba3579bd9f2"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### **`Dropping or Filling Missing Values`**\n",
                "\n",
                "#### Decision-Making Process:\n",
                "\n",
                "1. **Dropping Missing Values:**\n",
                "   - **Context:** Dropping missing values is suitable when the missingness is random, and removing incomplete records doesn't introduce bias or impact the analysis significantly. It's a pragmatic approach when the missing data is negligible compared to the dataset size.\n",
                "\n",
                "   - **Example:**\n",
                "     ```python\n",
                "     # Drop rows with any missing values\n",
                "     df_dropped = df.dropna()\n",
                "     ```\n",
                "\n",
                "2. **Filling Missing Values:**\n",
                "   - **Context:** Filling missing values is appropriate when retaining the incomplete records is crucial, and a reasonable estimation can be made for the missing values. This is common when dealing with time-series data, where continuity matters.\n",
                "\n",
                "   - **Example:**\n",
                "     ```python\n",
                "     # Fill missing values in 'column_name' with a constant value\n",
                "     df_filled_constant = df.fillna(value=0)\n",
                "     ```\n",
                "\n",
                "   - **Example:**\n",
                "     ```python\n",
                "     # Fill missing values with the mean of each column\n",
                "     df_filled_mean = df.fillna(df.mean())\n",
                "     ```\n",
                "\n",
                "   - **Example:**\n",
                "     ```python\n",
                "     # Forward fill missing values in a DataFrame\n",
                "     df_forward_filled = df.ffill()\n",
                "     ```\n",
                "\n",
                "   - **Example:**\n",
                "     ```python\n",
                "     # Backward fill missing values in a DataFrame\n",
                "     df_backward_filled = df.bfill()\n",
                "     ```\n",
                "\n",
                "   - **Example:**\n",
                "     ```python\n",
                "     # Interpolate missing values using linear interpolation\n",
                "     df_interpolated_linear = df.interpolate(method='linear')\n",
                "     ```\n",
                "\n",
                "#### Considerations:\n",
                "\n",
                "- **Data Nature:**\n",
                "  - Consider the nature of the data. For time-series data, forward or backward filling might be suitable, while for numeric data, mean or interpolation might be appropriate.\n",
                "\n",
                "- **Impact on Analysis:**\n",
                "  - Evaluate how the chosen method for handling missing values might impact subsequent analyses. Ensure that the imputation method aligns with the overall analysis goals.\n",
                "\n",
                "- **Domain Knowledge:**\n",
                "  - Leverage domain knowledge to make informed decisions. Some missing values may be inherently unfillable due to the nature of the data.\n",
                "\n",
                "#### Conclusion:\n",
                "\n",
                "The decision between dropping or filling missing values depends on the specific characteristics of the data and the analysis goals. Dropping values is a straightforward approach but may lead to data loss. Filling values is a more nuanced process, requiring careful consideration of the data's nature and the impact on downstream analyses. Experiment with different strategies and choose the one that best fits the context of your dataset."
            ],
            "metadata": {
                "azdata_cell_guid": "e23dce9b-8685-4281-9a73-9599a14ce32a"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Example:\n",
                "\n",
                "Let's consider a scenario where we have a DataFrame representing monthly sales data for a product. The dataset has missing values in the 'Sales' column, and we need to decide whether to drop or fill those missing values based on the context."
            ],
            "metadata": {
                "azdata_cell_guid": "4a804a23-6298-4019-ba92-db0dbfa66a3b"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Sample monthly sales data with missing values\n",
                "sales_data = {\n",
                "    'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],\n",
                "    'Sales': [100, 120, np.nan, 150, np.nan, 180],\n",
                "}\n",
                "\n",
                "# Creating a DataFrame from the sales data\n",
                "df_sales = pd.DataFrame(sales_data)\n",
                "\n",
                "# Displaying the original DataFrame\n",
                "print(\"Original Sales DataFrame:\")\n",
                "print(df_sales)\n",
                "\n",
                "# Decision 1: Dropping Missing Values\n",
                "df_dropped = df_sales.dropna()\n",
                "\n",
                "# Displaying the DataFrame after dropping missing values\n",
                "print(\"\\nDataFrame after Dropping Missing Values:\")\n",
                "print(df_dropped)\n",
                "\n",
                "# Decision 2: Filling Missing Values with Forward Fill\n",
                "df_filled_forward = df_sales.ffill()\n",
                "\n",
                "# Displaying the DataFrame after forward filling missing values\n",
                "print(\"\\nDataFrame after Forward Filling Missing Values:\")\n",
                "print(df_filled_forward)\n",
                "\n",
                "# Decision 3: Filling Missing Values with Mean\n",
                "df_filled_mean = df_sales.fillna(df_sales['Sales'].mean())\n",
                "\n",
                "# Displaying the DataFrame after filling missing values with mean\n",
                "print(\"\\nDataFrame after Filling Missing Values with Mean:\")\n",
                "print(df_filled_mean)\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "f6f5942f-a4fc-4300-8e92-2b2fade13559",
                "language": "python",
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Original Sales DataFrame:\n  Month  Sales\n0   Jan  100.0\n1   Feb  120.0\n2   Mar    NaN\n3   Apr  150.0\n4   May    NaN\n5   Jun  180.0\n\nDataFrame after Dropping Missing Values:\n  Month  Sales\n0   Jan  100.0\n1   Feb  120.0\n3   Apr  150.0\n5   Jun  180.0\n\nDataFrame after Forward Filling Missing Values:\n  Month  Sales\n0   Jan  100.0\n1   Feb  120.0\n2   Mar  120.0\n3   Apr  150.0\n4   May  150.0\n5   Jun  180.0\n\nDataFrame after Filling Missing Values with Mean:\n  Month  Sales\n0   Jan  100.0\n1   Feb  120.0\n2   Mar  137.5\n3   Apr  150.0\n4   May  137.5\n5   Jun  180.0\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "In this example:\n",
                "\n",
                "1. **Dropping Missing Values:**\n",
                "   - We use `dropna()` to remove rows with any missing values. This might be suitable if missing values are limited and their removal doesn't significantly affect the analysis.\n",
                "\n",
                "2. **Filling Missing Values with Forward Fill:**\n",
                "   - We use `ffill()` to fill missing values with the previous month's sales. This approach is reasonable when the missing values follow a pattern and can be reasonably estimated using existing data.\n",
                "\n",
                "3. **Filling Missing Values with Mean:**\n",
                "   - We use `fillna()` with the mean of the 'Sales' column to impute missing values. This approach is suitable when we want to retain all rows and fill missing values with a representative value.\n",
                "\n",
                "Adjust the code based on the specific characteristics of your dataset and the analysis goals. Choosing between dropping or filling missing values should be driven by the dataset's context and the impact on subsequent analyses."
            ],
            "metadata": {
                "azdata_cell_guid": "54303cda-e3c3-4f9a-86db-a2dd1e7cb05c"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Real-world Scenario:\n",
                "\n",
                "Imagine you are managing a dataset that tracks monthly sales data for a retail business. The dataset includes information such as the month, product category, sales quantity, and revenue. However, due to occasional reporting errors or data collection issues, there are missing values in the dataset. Let's explore how to handle these missing values using Pandas."
            ],
            "metadata": {
                "azdata_cell_guid": "fe7986f3-cb0f-4f6e-b308-153fe73b9586"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Sample monthly sales data with missing values\n",
                "sales_data = {\n",
                "    'Month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],\n",
                "    'Category': ['Electronics', 'Clothing', np.nan, 'Electronics', np.nan, 'Clothing'],\n",
                "    'Sales_Quantity': [120, 150, np.nan, 200, np.nan, 180],\n",
                "    'Revenue': [12000, np.nan, 18000, np.nan, 25000, 22000],\n",
                "}\n",
                "\n",
                "# Creating a DataFrame from the sales data\n",
                "df_sales = pd.DataFrame(sales_data)\n",
                "\n",
                "# Displaying the original DataFrame\n",
                "print(\"Original Monthly Sales DataFrame:\")\n",
                "print(df_sales)\n",
                "\n",
                "# Handling Missing Values:\n",
                "# Decision 1: Dropping rows with any missing values\n",
                "df_dropped = df_sales.dropna()\n",
                "\n",
                "# Decision 2: Filling missing values with mean for numerical columns\n",
                "df_filled_mean = df_sales.fillna({'Sales_Quantity': df_sales['Sales_Quantity'].mean(), 'Revenue': df_sales['Revenue'].mean()})\n",
                "\n",
                "# Displaying the DataFrames after handling missing values\n",
                "print(\"\\nDataFrame after Dropping Missing Values:\")\n",
                "print(df_dropped)\n",
                "\n",
                "print(\"\\nDataFrame after Filling Missing Values with Mean:\")\n",
                "print(df_filled_mean)\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "50df0c3a-ef78-4a40-9ac2-4e19048b3a83",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Original Monthly Sales DataFrame:\n  Month     Category  Sales_Quantity  Revenue\n0   Jan  Electronics           120.0  12000.0\n1   Feb     Clothing           150.0      NaN\n2   Mar          NaN             NaN  18000.0\n3   Apr  Electronics           200.0      NaN\n4   May          NaN             NaN  25000.0\n5   Jun     Clothing           180.0  22000.0\n\nDataFrame after Dropping Missing Values:\n  Month     Category  Sales_Quantity  Revenue\n0   Jan  Electronics           120.0  12000.0\n5   Jun     Clothing           180.0  22000.0\n\nDataFrame after Filling Missing Values with Mean:\n  Month     Category  Sales_Quantity  Revenue\n0   Jan  Electronics           120.0  12000.0\n1   Feb     Clothing           150.0  19250.0\n2   Mar          NaN           162.5  18000.0\n3   Apr  Electronics           200.0  19250.0\n4   May          NaN           162.5  25000.0\n5   Jun     Clothing           180.0  22000.0\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 4
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Considerations or Peculiarities:\n",
                "\n",
                "- **Imputation Strategy:**\n",
                "  - Choosing between dropping and filling depends on the impact on analysis. Dropping may lead to loss of important information, while filling may introduce bias if not done carefully.\n",
                "\n",
                "- **Context of Data:**\n",
                "  - Understand the context of your data. For example, filling missing revenue values with the mean might be reasonable, but for product categories, it may not make sense.\n",
                "\n",
                "- **Column-specific Strategies:**\n",
                "  - Different columns may require different strategies. For numeric columns, mean or median filling could be appropriate, while for categorical columns, forward fill or mode filling might be more suitable.\n",
                "\n",
                "#### Common Mistakes:\n",
                "\n",
                "- **Unintended Data Loss:**\n",
                "  - Developers might drop rows without considering the impact on the dataset's integrity. This can lead to unintended data loss, especially if the missing values are not randomly distributed.\n",
                "\n",
                "- **Inconsistent Imputation:**\n",
                "  - Filling missing values inconsistently across columns or datasets can introduce inconsistencies in the dataset.\n",
                "\n",
                "- **Overlooking Context:**\n",
                "  - Filling missing values without understanding the context of the data and the reasons for missingness may lead to inaccurate imputations.\n",
                "\n",
                "Handling missing values is a critical aspect of data preprocessing. It requires thoughtful consideration of the dataset's context, the nature of missingness, and the impact on downstream analyses. Developers should choose strategies that align with the goals of their analysis and avoid common pitfalls that can compromise data quality."
            ],
            "metadata": {
                "azdata_cell_guid": "4c758e06-d227-4fa8-8c34-10fe46608bcc"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### **`Removing Duplicates in a DataFrame`**\n",
                "\n",
                "#### Significance of Identifying and Removing Duplicate Rows:\n",
                "\n",
                "**1. Data Accuracy:**\n",
                "   - Duplicate rows can distort analyses by inflating counts, averages, or other summary statistics. Removing duplicates ensures the accuracy of calculated metrics.\n",
                "\n",
                "**2. Consistent Results:**\n",
                "   - Duplicates can lead to inconsistencies in results, especially in scenarios where aggregated data or distinct counts are essential.\n",
                "\n",
                "**3. Efficient Memory Usage:**\n",
                "   - Datasets with duplicate rows consume more memory. Eliminating duplicates optimizes memory usage and enhances computational efficiency.\n",
                "\n",
                "**4. Meaningful Insights:**\n",
                "   - Duplicate rows may not contribute meaningful insights but can skew results. Removing them ensures a cleaner dataset for analysis.\n",
                "\n",
                "#### Examples of Removing Duplicates:\n",
                "\n",
                "**1. Identifying Duplicate Rows:**\n",
                "```python\n",
                "# Check for duplicate rows based on all columns\n",
                "duplicates = df.duplicated()\n",
                "\n",
                "# Check for duplicate rows based on specific columns\n",
                "duplicates_specific_columns = df.duplicated(subset=['Column1', 'Column2'])\n",
                "```\n",
                "\n",
                "**2. Removing Duplicate Rows:**\n",
                "```python\n",
                "# Remove all duplicate rows, keeping the first occurrence\n",
                "df_no_duplicates = df.drop_duplicates()\n",
                "\n",
                "# Remove duplicate rows based on specific columns, keeping the first occurrence\n",
                "df_no_duplicates_specific_columns = df.drop_duplicates(subset=['Column1', 'Column2'])\n",
                "```\n",
                "\n",
                "#### Considerations:\n",
                "\n",
                "- **Column Selection:**\n",
                "  - Consider the columns relevant to duplicate identification. In some cases, duplicates may only be duplicates when considering specific columns.\n",
                "\n",
                "- **Order Matters:**\n",
                "  - `drop_duplicates()` retains the first occurrence and removes subsequent duplicates. Ensure the order aligns with your analysis goals.\n",
                "\n",
                "- **In-Place vs. New DataFrame:**\n",
                "  - Decide whether to modify the existing DataFrame in-place or create a new one. Choose based on the need to retain the original data.\n",
                "\n",
                "#### Common Mistakes:\n",
                "\n",
                "- **Ignoring Specific Columns:**\n",
                "  - Failing to specify columns during duplicate checking can result in unintended removal of rows that might be duplicates only in certain columns.\n",
                "\n",
                "- **Overlooking Order:**\n",
                "  - If retaining the first occurrence is essential, ensure that the DataFrame is sorted appropriately before using `drop_duplicates()`.\n",
                "\n",
                "- **Inconsistent Usage:**\n",
                "  - Inconsistently applying duplicate removal across different datasets or analyses can lead to inconsistent results.\n",
                "\n",
                "#### Conclusion:\n",
                "\n",
                "Identifying and removing duplicate rows is a crucial step in data cleaning and preprocessing. It enhances the accuracy of analyses, ensures meaningful insights, and optimizes memory usage. Developers should carefully consider the columns involved, the order of removal, and whether to modify the DataFrame in-place when handling duplicates."
            ],
            "metadata": {
                "azdata_cell_guid": "87fbb7b1-d617-4116-8a09-6ae80fb31268"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Example:\n",
                "\n",
                "Let's consider a scenario where you have a DataFrame containing data on customer orders, and due to data entry errors or system glitches, there are duplicate entries. We'll explore how to identify and remove these duplicate rows using Pandas."
            ],
            "metadata": {
                "azdata_cell_guid": "17603c35-4823-46e3-a320-43b8a6fe4613"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Sample order data with duplicate entries\n",
                "order_data = {\n",
                "    'OrderID': [101, 102, 101, 103, 104, 102],\n",
                "    'Product': ['Laptop', 'Smartphone', 'Laptop', 'Tablet', 'Camera', 'Smartphone'],\n",
                "    'Quantity': [2, 1, 1, 3, 1, 1],\n",
                "    'Total_Price': [1200, 800, 1200, 450, 700, 800],\n",
                "}\n",
                "\n",
                "# Creating a DataFrame from the order data\n",
                "df_orders = pd.DataFrame(order_data)\n",
                "\n",
                "# Displaying the original DataFrame\n",
                "print(\"Original Order DataFrame:\")\n",
                "print(df_orders)\n",
                "\n",
                "# Identifying Duplicate Rows\n",
                "duplicates = df_orders.duplicated()\n",
                "\n",
                "# Displaying duplicate rows\n",
                "print(\"\\nDuplicate Rows:\")\n",
                "print(df_orders[duplicates])\n",
                "\n",
                "# Removing Duplicate Rows\n",
                "df_no_duplicates = df_orders.drop_duplicates()\n",
                "\n",
                "# Displaying the DataFrame after removing duplicates\n",
                "print(\"\\nDataFrame after Removing Duplicates:\")\n",
                "print(df_no_duplicates)\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "15f714f1-2d65-4dbc-ae80-c9641ab6c80e",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Original Order DataFrame:\n   OrderID     Product  Quantity  Total_Price\n0      101      Laptop         2         1200\n1      102  Smartphone         1          800\n2      101      Laptop         1         1200\n3      103      Tablet         3          450\n4      104      Camera         1          700\n5      102  Smartphone         1          800\n\nDuplicate Rows:\n   OrderID     Product  Quantity  Total_Price\n5      102  Smartphone         1          800\n\nDataFrame after Removing Duplicates:\n   OrderID     Product  Quantity  Total_Price\n0      101      Laptop         2         1200\n1      102  Smartphone         1          800\n2      101      Laptop         1         1200\n3      103      Tablet         3          450\n4      104      Camera         1          700\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "In this example:\n",
                "\n",
                "1. **Identifying Duplicate Rows:**\n",
                "   - We use `duplicated()` to identify duplicate rows based on all columns. The result is a boolean series indicating which rows are duplicates.\n",
                "\n",
                "2. **Displaying Duplicate Rows:**\n",
                "   - We use boolean indexing to display the rows that are identified as duplicates.\n",
                "\n",
                "3. **Removing Duplicate Rows:**\n",
                "   - We use `drop_duplicates()` to remove duplicate rows, keeping the first occurrence of each unique row.\n",
                "\n",
                "4. **Displaying Result:**\n",
                "   - We display the DataFrame after removing duplicates to see the cleaned dataset.\n",
                "\n",
                "Adjust the code based on your specific dataset and analysis goals. Understanding the significance of removing duplicates and applying these methods ensures a cleaner and more reliable dataset for further analysis."
            ],
            "metadata": {
                "azdata_cell_guid": "cac6b593-3ba6-4758-a26b-462a39cd6b13"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "#### Considerations or Peculiarities:\n",
                "\n",
                "- **Column Selection:**\n",
                "  - Consider which columns should be considered for identifying duplicates. In some cases, duplicates may only be duplicates when considering specific columns.\n",
                "\n",
                "- **Impact on Analysis:**\n",
                "  - Consider how duplicate rows might impact subsequent analyses. Retaining duplicates might skew results, while removing them ensures a cleaner dataset.\n",
                "\n",
                "#### Common Mistakes:\n",
                "\n",
                "- **Incomplete Duplicate Identification:**\n",
                "  - Not considering all relevant columns during duplicate identification might result in incomplete removal of duplicates.\n",
                "\n",
                "- **Ignoring Context:**\n",
                "  - Failing to understand the context of the data might lead to unintended removal of rows that may be legitimate duplicates.\n",
                "\n",
                "- **Overlooking Order:**\n",
                "  - Forgetting to sort the DataFrame appropriately before using `drop_duplicates()` may lead to unexpected results if order matters.\n",
                "\n",
                "Handling duplicate rows is essential for maintaining data accuracy and ensuring meaningful analyses. Developers should carefully choose columns for duplicate identification, understand the impact of duplicates on analysis, and avoid common mistakes that could compromise data integrity."
            ],
            "metadata": {
                "azdata_cell_guid": "0f45b52c-2939-4678-bacc-867f0e58cb6a"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **`Hands On Experience:`**\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "94d5691b-44e0-4f6a-a220-7abe1601cb3a"
            },
            "attachments": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Question 1: Creating a DataFrame from Lists and Basic Operations\n",
                "\n",
                "#### Scenario:\n",
                "You have information about monthly sales for a retail store. Each list contains data for a different month.\n",
                "\n",
                "```python\n",
                "# Data for three months\n",
                "months = ['Jan', 'Feb', 'Mar']\n",
                "sales = [1200, 1500, 1800]\n",
                "expenses = [800, 900, 1000]\n",
                "\n",
                "# Question:\n",
                "# Create a DataFrame named 'df_sales' from these lists, and display the DataFrame.\n",
                "# Calculate the profit for each month (Profit = Sales - Expenses).\n",
                "# Display the DataFrame after adding the 'Profit' column.\n",
                "```"
            ],
            "metadata": {
                "azdata_cell_guid": "79db4844-cef0-46a5-9ba7-22893d318d4a"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Data for three months\n",
                "months = ['Jan', 'Feb', 'Mar']\n",
                "sales = [1200, 1500, 1800]\n",
                "expenses = [800, 900, 1000]\n",
                "\n",
                "import pandas as pd\n",
                "\n",
                "# Creating a DataFrame from Lists\n",
                "df_sales = pd.DataFrame({'Month': months, 'Sales': sales, 'Expenses': expenses})\n",
                "\n",
                "# Calculating Profit\n",
                "df_sales['Profit'] = df_sales['Sales'] - df_sales['Expenses']\n",
                "\n",
                "# Displaying the DataFrame\n",
                "print(\"DataFrame after Creating and Calculating Profit:\")\n",
                "print(df_sales)"
            ],
            "metadata": {
                "azdata_cell_guid": "bbaedd7b-8d6f-48a2-b265-48b03e4e8714",
                "language": "python"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "DataFrame after Creating and Calculating Profit:\n  Month  Sales  Expenses  Profit\n0   Jan   1200       800     400\n1   Feb   1500       900     600\n2   Mar   1800      1000     800\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Question 2: Reading Data from CSV and Descriptive Statistics\n",
                "\n",
                "#### Scenario:\n",
                "\n",
                "Let's assume you have a CSV file named 'sales_data.csv' with the following structure:\n",
                "\n",
                "```csv\n",
                "Product,Quantity,Revenue\n",
                "Laptop,10,12000\n",
                "Smartphone,5,8000\n",
                "Tablet,,4500\n",
                "Camera,3,\n",
                "```\n",
                "\n",
                "You have a CSV file named 'sales_data.csv' containing information about product sales. Read the data into a DataFrame and perform descriptive statistics.\n",
                "\n",
                "```python\n",
                "# Question:\n",
                "# Read 'sales_data.csv' into a DataFrame named 'df_sales'.\n",
                "# Display the first 5 rows of the DataFrame.\n",
                "# Calculate basic descriptive statistics for the 'Quantity' column.\n",
                "```\n",
                "\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "695e1494-99b6-4103-a447-624160df08bf"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Reading Data from CSV\n",
                "df_sales = pd.read_csv('sales_data.csv')\n",
                "\n",
                "# Displaying the first 5 rows\n",
                "print(\"First 5 Rows of df_sales:\")\n",
                "print(df_sales.head())\n",
                "\n",
                "# Descriptive Statistics for 'Quantity'\n",
                "quantity_stats = df_sales['Quantity'].describe()\n",
                "print(\"\\nDescriptive Statistics for 'Quantity':\")\n",
                "print(quantity_stats)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "ceee1d6f-2936-48f0-9062-f5ef6c0fdb3c"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "First 5 Rows of df_sales:\n      Product  Quantity  Revenue\n0      Laptop      10.0  12000.0\n1  Smartphone       5.0   8000.0\n2      Tablet       NaN   4500.0\n3      Camera       3.0      NaN\n\nDescriptive Statistics for 'Quantity':\ncount     3.000000\nmean      6.000000\nstd       3.605551\nmin       3.000000\n25%       4.000000\n50%       5.000000\n75%       7.500000\nmax      10.000000\nName: Quantity, dtype: float64\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Question 3: Handling Missing Values and Filling with Mean\n",
                "\n",
                "#### Scenario:\n",
                "Your DataFrame has missing values in the 'Revenue' column. Handle the missing values by filling them with the mean.\n",
                "\n",
                "```python\n",
                "# Question:\n",
                "# Handle missing values in the 'Revenue' column by filling them with the mean.\n",
                "# Display the DataFrame after handling missing values.\n",
                "```"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "22f64737-e7a5-4e7c-9829-e76067f1e464"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Handling Missing Values in 'Revenue'\n",
                "df_sales['Revenue'].fillna(df_sales['Revenue'].mean(), inplace=True)\n",
                "\n",
                "# Displaying the DataFrame after Handling Missing Values\n",
                "print(\"DataFrame after Handling Missing Values in 'Revenue':\")\n",
                "print(df_sales)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "46a353ec-11e1-4838-b689-f7958f23831f"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "DataFrame after Handling Missing Values in 'Revenue':\n      Product  Quantity       Revenue\n0      Laptop      10.0  12000.000000\n1  Smartphone       5.0   8000.000000\n2      Tablet       NaN   4500.000000\n3      Camera       3.0   8166.666667\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Question 4: Removing Duplicates\n",
                "\n",
                "#### Scenario:\n",
                "Your DataFrame 'df_orders' contains duplicate entries for customer orders. Remove the duplicates based on all columns.\n",
                "\n",
                "```python\n",
                "# Question:\n",
                "# Identify and remove duplicate rows from 'df_orders'.\n",
                "# Display the DataFrame after removing duplicates.\n",
                "```"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "6149a71a-a368-43b6-b9e9-3cd06bd4d108"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Identifying Duplicate Rows\n",
                "duplicates = df_orders.duplicated()\n",
                "\n",
                "# Removing Duplicate Rows\n",
                "df_orders_no_duplicates = df_orders.drop_duplicates()\n",
                "\n",
                "# Displaying the DataFrame after Removing Duplicates\n",
                "print(\"DataFrame after Removing Duplicates:\")\n",
                "print(df_orders_no_duplicates)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "9235c29a-25ab-49fc-8331-b8345a680d31"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "DataFrame after Removing Duplicates:\n   OrderID     Product  Quantity  Total_Price\n0      101      Laptop         2         1200\n1      102  Smartphone         1          800\n2      101      Laptop         1         1200\n3      103      Tablet         3          450\n4      104      Camera         1          700\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "### Question 5: Conditional Indexing and Filtering\n",
                "\n",
                "#### Scenario:\n",
                "You want to analyze only the orders with a quantity greater than 2.\n",
                "\n",
                "```python\n",
                "# Question:\n",
                "# Create a new DataFrame 'df_large_orders' containing only the orders with Quantity greater than 2.\n",
                "# Display the new DataFrame.\n",
                "```"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "e94d7540-a640-4408-85ab-1ec9422cf5fc"
            },
            "attachments": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Conditional Indexing and Filtering\n",
                "df_large_orders = df_orders[df_orders['Quantity'] > 2]\n",
                "\n",
                "# Displaying the DataFrame with Large Orders\n",
                "print(\"DataFrame with Orders Quantity > 2:\")\n",
                "print(df_large_orders)"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "7df8f752-c4d0-4cbe-a545-b7d820411a6d"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "DataFrame with Orders Quantity > 2:\n   OrderID Product  Quantity  Total_Price\n3      103  Tablet         3          450\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 10
        }
    ]
}